# parsers/sources/championat/parsers/sports_parser.py

import aiohttp
import sqlite3
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import asyncio # –î–ª—è asyncio.sleep
import os # –î–ª—è os.path.dirname
import yaml # –î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥–∞ (–≤—Ä–µ–º–µ–Ω–Ω–æ, –ø–æ—Ç–æ–º –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å—Å—è)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±—â—É—é –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
from parsers.sources.championat.utils import fetch_page

# === –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö ===
def insert_sport(cursor, name, slug, url):
    """
    –í—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π –≤–∏–¥ —Å–ø–æ—Ä—Ç–∞ –≤ –ë–î –∏–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç ID —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ.
    """
    try:
        cursor.execute("INSERT OR IGNORE INTO sports (name, slug, url) VALUES (?, ?, ?)", (name, slug, url))
        if cursor.lastrowid:
            print(f"  ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –≤–∏–¥ —Å–ø–æ—Ä—Ç–∞: {name} (ID: {cursor.lastrowid})")
            return cursor.lastrowid
        else:
            cursor.execute("SELECT id FROM sports WHERE url = ?", (url,))
            existing_id = cursor.fetchone()
            if existing_id:
                # print(f"  ‚ÑπÔ∏è –í–∏–¥ —Å–ø–æ—Ä—Ç–∞ '{name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (ID: {existing_id[0]}).")
                return existing_id[0]
            else:
                print(f"  ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –≤–∏–¥ —Å–ø–æ—Ä—Ç–∞ '{name}'.")
                return None
    except sqlite3.Error as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—Å—Ç–∞–≤–∫–µ –≤–∏–¥–∞ —Å–ø–æ—Ä—Ç–∞ '{name}': {e}")
        return None

# === –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–∏–¥–æ–≤ —Å–ø–æ—Ä—Ç–∞ ===
async def parse_sports(session, base_url, parser_cfg):
    """
    –ü–∞—Ä—Å–∏—Ç —Å–ø–∏—Å–æ–∫ –≤–∏–¥–æ–≤ —Å–ø–æ—Ä—Ç–∞ —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã Championat.com.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤–∏–¥–∞—Ö —Å–ø–æ—Ä—Ç–∞.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –∏–∑ parser_cfg.
    """
    print(f"--- –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –≤–∏–¥–æ–≤ —Å–ø–æ—Ä—Ç–∞ —Å {base_url} ---")
    html = await fetch_page(session, base_url)
    if not html:
        print("ü§∑ –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å HTML –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–∏–¥–æ–≤ —Å–ø–æ—Ä—Ç–∞.")
        return []

    soup = BeautifulSoup(html, 'lxml')
    sports = []
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –∏–∑ parser_cfg
    sport_elements = soup.select(parser_cfg["sport_item_selector"])

    for el in sport_elements:
        name_el = el.select_one(parser_cfg["sport_link_selector"])
        if name_el:
            name = name_el.get_text(strip=True)
            url = urljoin(base_url, name_el.get("href"))
            slug = el.get("data-label") # data-label –ø–æ–∫–∞ –æ—Å—Ç–∞–µ—Ç—Å—è –∑–¥–µ—Å—å, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –∞—Ç—Ä–∏–±—É—Ç —ç–ª–µ–º–µ–Ω—Ç–∞

            # –ò—Å–∫–ª—é—á–∞–µ–º –æ–±—â–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –≤–∏–¥–∞–º–∏ —Å–ø–æ—Ä—Ç–∞
            if name and url and slug and name.lower() not in ["–¥—Ä—É–≥–∏–µ", "—á–µ–º–ø.play", "—Å—Ç–∞–≤–∫–∏", "lifestyle", "–æ–ª–∏–º–ø–∏–∞–¥–∞ 2026", "–≤–æ–¥–Ω—ã–π —á–º 2025"]:
                sports.append({"name": name, "slug": slug, "url": url})

    print(f"  ‚úÖ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(sports)} –≤–∏–¥–æ–≤ —Å–ø–æ—Ä—Ç–∞.")
    return sports

# === –ù–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∏–¥–æ–≤ —Å–ø–æ—Ä—Ç–∞ ===
async def load_and_save_sports(session, cursor, config):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤–∏–¥—ã —Å–ø–æ—Ä—Ç–∞ —Å Championat.com –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Ö –≤ –ë–î.
    """
    print("\n--- –ó–∞–ø—É—Å–∫ –º–æ–¥—É–ª—è: –ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∏–¥–æ–≤ —Å–ø–æ—Ä—Ç–∞ ---")
    sports_list = await parse_sports(session, config["url"], config["selectors"])
    if sports_list:
        print(f"  –ù–∞–π–¥–µ–Ω–æ {len(sports_list)} –≤–∏–¥–æ–≤ —Å–ø–æ—Ä—Ç–∞ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏.")
        for sport in sports_list:
            insert_sport(cursor, sport["name"], sport["slug"], sport["url"])
        print(f"  ‚úÖ –í–∏–¥—ã —Å–ø–æ—Ä—Ç–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—é.")
    else:
        print("  ü§∑ –í–∏–¥—ã —Å–ø–æ—Ä—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞.")

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥—É–ª—è –æ—Ç–¥–µ–ª—å–Ω–æ)
async def main():
    # –í—Ä–µ–º–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'sources_config.yml')
    if not os.path.exists(config_path):
        print(f"–û—à–∏–±–∫–∞: sources_config.yml –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏ {config_path}")
        return
    try:
        with open(config_path, encoding="utf-8") as f:
            all_config = yaml.safe_load(f)
        config = all_config["championat"]
        print("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è championat.com –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ.")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        return

    db_path = "database/prosport.db" # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–π db_path
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"
    }

    async with aiohttp.ClientSession(headers=headers) as session:
        await load_and_save_sports(session, cursor, config)
        conn.commit() # –ö–æ–º–º–∏—Ç –ø—Ä–∏ –ª–æ–∫–∞–ª—å–Ω–æ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏
        print("–õ–æ–∫–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ sports_parser –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
    conn.close()

if __name__ == "__main__":
    asyncio.run(main())
